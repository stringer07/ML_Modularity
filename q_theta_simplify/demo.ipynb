{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c379ada",
   "metadata": {},
   "source": [
    "**This is a script for quickly demonstrating the capability of model reduction for the $q–\\theta$ function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b3140",
   "metadata": {},
   "source": [
    "## 1. Import essential libraries and initialize the required environment setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f11155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import sympy as sp\n",
    "from src.utils import AttrDict\n",
    "from src.envs import build_env\n",
    "import linecache\n",
    "import mpmath as mp\n",
    "import numpy as np\n",
    "\n",
    "params = AttrDict({\n",
    "\n",
    "    # environment parameters\n",
    "    'env_name': 'char_sp',\n",
    "    'int_base': 10,\n",
    "    'balanced': False,\n",
    "    'positive': True,\n",
    "    'precision': 10,\n",
    "    'n_variables': 1,\n",
    "    'n_coefficients': 0,\n",
    "    'leaf_probs': '0.75,0,0.25,0',\n",
    "    'max_len': 512,\n",
    "    'max_int': 5,\n",
    "    'max_ops': 15,\n",
    "    'max_ops_G': 15,\n",
    "    'clean_prefix_expr': True,\n",
    "    'rewrite_functions': '',\n",
    "    'tasks': 'prim_fwd',\n",
    "    'operators': 'add:10,sub:3,mul:10,div:5,sqrt:4,pow2:4,pow3:2,pow4:1,pow5:1,ln:4,exp:4,sin:4,cos:4,tan:4,asin:1,acos:1,atan:1,sinh:1,cosh:1,tanh:1,asinh:1,acosh:1,atanh:1',\n",
    "})\n",
    "\n",
    "env = build_env(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63783f5a",
   "metadata": {},
   "source": [
    "## 2. Load model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4eb7671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"./results/random_ns_nt\" # model path to your trained model\n",
    "tokenizer_path=\"./results/random_ns_nt\" # tokenizer path to your trained model (usually the same as model path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4caabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model)\n",
    "\n",
    "device='cuda'\n",
    "model=model.to(device)\n",
    "model=model.eval()\n",
    "def generate_summary(input_tokens):\n",
    "    inputs = tokenizer(input_tokens, return_tensors=\"pt\",is_split_into_words=True, padding=True, truncation=True)\n",
    "    if device =='cuda':\n",
    "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
    "        outputs = model.generate(inputs['input_ids'], max_length=512, num_beams=2, early_stopping=True)\n",
    "    else:\n",
    "        outputs = model.generate(inputs.input_ids, max_length=512, num_beams=2, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab2e76",
   "metadata": {},
   "source": [
    "## 3. Use model to simplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ec6ca",
   "metadata": {},
   "source": [
    "**You can use your own expression here, expression can be generated using the script in `./data_process/datagenerate.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339c09fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original expression (infix): q_theta(z/(t - 1), (8*t - 9)/(t - 1))*q_theta(z/(t + 1), t/(t + 1))*q_theta(-z/(5*t - 9), (6*t - 11)/(5*t - 9))*q_theta(-z/(6*t + 11), (-t - 2)/(6*t + 11))*q_theta(z/(20*t - 9), (11*t - 5)/(20*t - 9))/(q_theta(-z/(4*t + 1), (-3*t - 1)/(4*t + 1))*q_theta(-z/(8*t + 1), (33*t + 4)/(8*t + 1))*q_theta(-z/(9*t - 4), (11*t - 5)/(9*t - 4))*q_theta(-z/(19*t + 34), (14*t + 25)/(19*t + 34)))\n",
      "Original expression (prefix): ['mul', 'pow', 'q_theta', 'mul', 'INT-', '1', 'mul', 'z', 'pow', 'add', 'INT+', '1', 'mul', 'INT+', '4', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT+', '1', 'mul', 'INT+', '4', 't', 'INT-', '1', 'add', 'INT-', '1', 'mul', 'INT-', '3', 't', 'INT-', '1', 'mul', 'pow', 'q_theta', 'mul', 'INT-', '1', 'mul', 'z', 'pow', 'add', 'INT+', '1', 'mul', 'INT+', '8', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT+', '1', 'mul', 'INT+', '8', 't', 'INT-', '1', 'add', 'INT+', '4', 'mul', 'INT+', '3', '3', 't', 'INT-', '1', 'mul', 'pow', 'q_theta', 'mul', 'INT-', '1', 'mul', 'z', 'pow', 'add', 'INT-', '4', 'mul', 'INT+', '9', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT-', '4', 'mul', 'INT+', '9', 't', 'INT-', '1', 'add', 'INT-', '5', 'mul', 'INT+', '1', '1', 't', 'INT-', '1', 'mul', 'pow', 'q_theta', 'mul', 'INT-', '1', 'mul', 'z', 'pow', 'add', 'INT+', '3', '4', 'mul', 'INT+', '1', '9', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT+', '3', '4', 'mul', 'INT+', '1', '9', 't', 'INT-', '1', 'add', 'INT+', '2', '5', 'mul', 'INT+', '1', '4', 't', 'INT-', '1', 'mul', 'q_theta', 'mul', 'z', 'pow', 'add', 'INT+', '1', 't', 'INT-', '1', 'mul', 't', 'pow', 'add', 'INT+', '1', 't', 'INT-', '1', 'mul', 'q_theta', 'mul', 'z', 'pow', 'add', 'INT-', '1', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT-', '1', 't', 'INT-', '1', 'add', 'INT-', '9', 'mul', 'INT+', '8', 't', 'mul', 'q_theta', 'mul', 'z', 'pow', 'add', 'INT-', '9', 'mul', 'INT+', '2', '0', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT-', '9', 'mul', 'INT+', '2', '0', 't', 'INT-', '1', 'add', 'INT-', '5', 'mul', 'INT+', '1', '1', 't', 'mul', 'q_theta', 'mul', 'INT-', '1', 'mul', 'z', 'pow', 'add', 'INT-', '9', 'mul', 'INT+', '5', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT-', '9', 'mul', 'INT+', '5', 't', 'INT-', '1', 'add', 'INT-', '1', '1', 'mul', 'INT+', '6', 't', 'q_theta', 'mul', 'INT-', '1', 'mul', 'z', 'pow', 'add', 'INT+', '1', '1', 'mul', 'INT+', '6', 't', 'INT-', '1', 'mul', 'pow', 'add', 'INT+', '1', '1', 'mul', 'INT+', '6', 't', 'INT-', '1', 'add', 'INT-', '2', 'mul', 'INT-', '1', 't']\n"
     ]
    }
   ],
   "source": [
    "expr_origin_infix = \"q_theta(z/(t - 1), (8*t - 9)/(t - 1))*q_theta(z/(t + 1), t/(t + 1))*q_theta(-z/(5*t - 9), (6*t - 11)/(5*t - 9))*q_theta(-z/(6*t + 11), (-t - 2)/(6*t + 11))*q_theta(z/(20*t - 9), (11*t - 5)/(20*t - 9))/(q_theta(-z/(4*t + 1), (-3*t - 1)/(4*t + 1))*q_theta(-z/(8*t + 1), (33*t + 4)/(8*t + 1))*q_theta(-z/(9*t - 4), (11*t - 5)/(9*t - 4))*q_theta(-z/(19*t + 34), (14*t + 25)/(19*t + 34)))\"\n",
    "expr_sp_origin = sp.S(expr_origin_infix, locals=env.local_dict)\n",
    "expr_origin_prefix = env.sympy_to_prefix(expr_sp_origin)\n",
    "print(\"Original expression (infix):\", expr_origin_infix)\n",
    "print(\"Original expression (prefix):\", expr_origin_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5b5cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: q_theta(-z/(t - 1), (7*t - 8)/(t - 1))*q_theta(-z/(5*t - 9), (t - 2)/(5*t - 9))/q_theta(-z/(8*t + 1), (9*t + 1)/(8*t + 1))\n"
     ]
    }
   ],
   "source": [
    "after_train_str = generate_summary(expr_origin_prefix)\n",
    "after_train_prefix = after_train_str.split(\" \")\n",
    "\n",
    "after_train_infix = env.prefix_to_infix(after_train_prefix)\n",
    "after_train_sp = env.infix_to_sympy(after_train_infix)\n",
    "\n",
    "predicted_str = str(after_train_sp)\n",
    "print(\"Model prediction:\", predicted_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364f8387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{q_{\\theta}{\\left(\\frac{z}{t - 1},\\frac{8 t - 9}{t - 1} \\right)} q_{\\theta}{\\left(\\frac{z}{t + 1},\\frac{t}{t + 1} \\right)} q_{\\theta}{\\left(- \\frac{z}{5 t - 9},\\frac{6 t - 11}{5 t - 9} \\right)} q_{\\theta}{\\left(- \\frac{z}{6 t + 11},\\frac{- t - 2}{6 t + 11} \\right)} q_{\\theta}{\\left(\\frac{z}{20 t - 9},\\frac{11 t - 5}{20 t - 9} \\right)}}{q_{\\theta}{\\left(- \\frac{z}{4 t + 1},\\frac{- 3 t - 1}{4 t + 1} \\right)} q_{\\theta}{\\left(- \\frac{z}{8 t + 1},\\frac{33 t + 4}{8 t + 1} \\right)} q_{\\theta}{\\left(- \\frac{z}{9 t - 4},\\frac{11 t - 5}{9 t - 4} \\right)} q_{\\theta}{\\left(- \\frac{z}{19 t + 34},\\frac{14 t + 25}{19 t + 34} \\right)}}$"
      ],
      "text/plain": [
       "q_theta(z/(t - 1), (8*t - 9)/(t - 1))*q_theta(z/(t + 1), t/(t + 1))*q_theta(-z/(5*t - 9), (6*t - 11)/(5*t - 9))*q_theta(-z/(6*t + 11), (-t - 2)/(6*t + 11))*q_theta(z/(20*t - 9), (11*t - 5)/(20*t - 9))/(q_theta(-z/(4*t + 1), (-3*t - 1)/(4*t + 1))*q_theta(-z/(8*t + 1), (33*t + 4)/(8*t + 1))*q_theta(-z/(9*t - 4), (11*t - 5)/(9*t - 4))*q_theta(-z/(19*t + 34), (14*t + 25)/(19*t + 34)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before simplification\n",
    "expr_sp_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d997c74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{q_{\\theta}{\\left(- \\frac{z}{t - 1},\\frac{7 t - 8}{t - 1} \\right)} q_{\\theta}{\\left(- \\frac{z}{5 t - 9},\\frac{t - 2}{5 t - 9} \\right)}}{q_{\\theta}{\\left(- \\frac{z}{8 t + 1},\\frac{9 t + 1}{8 t + 1} \\right)}}$"
      ],
      "text/plain": [
       "q_theta(-z/(t - 1), (7*t - 8)/(t - 1))*q_theta(-z/(5*t - 9), (t - 2)/(5*t - 9))/q_theta(-z/(8*t + 1), (9*t + 1)/(8*t + 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After simplification\n",
    "after_train_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc1770",
   "metadata": {},
   "source": [
    "## 4. Check the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "757df722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define some key functions\n",
    "mp.dps = 30  \n",
    "\n",
    "def theta_q_jtheta(z, tau):\n",
    "    z = mp.mpc(z)\n",
    "    tau = mp.mpc(tau)\n",
    "    Q_jacobi = mp.exp(mp.pi * 1j * tau) \n",
    "    q_img = Q_jacobi**2  \n",
    "    w = mp.pi * z\n",
    "\n",
    "    j1 = mp.jtheta(1, w, Q_jacobi)\n",
    "    \n",
    "    prefactor = 1j * (Q_jacobi**0.25) * mp.exp(-1j * mp.pi * z)\n",
    "    eta_prod = mp.qp(q_img) \n",
    "    \n",
    "    return j1 / (prefactor * eta_prod)\n",
    "\n",
    "def theta_q_safe(z, tau):\n",
    "    return theta_q_jtheta(z, tau)\n",
    "\n",
    "def q_theta(z, tau):\n",
    "    return theta_q_safe(z, tau)\n",
    "\n",
    "\n",
    "def get_log_derivative(expr_str, z0, t_val, h=1e-5):\n",
    "\n",
    "    context = {\n",
    "        'q_theta': q_theta,\n",
    "        'theta_q_safe': theta_q_safe,\n",
    "        'z': None, \n",
    "        't': t_val,\n",
    "        'I': 1j,\n",
    "        'mp': mp\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Calculate f(z0)\n",
    "        context['z'] = z0\n",
    "        f_0 = complex(eval(expr_str, {\"__builtins__\": None}, context))\n",
    "        \n",
    "        if abs(f_0) < 1e-12: return None # Avoid singularities/zeros\n",
    "\n",
    "        # Calculate f(z0 + h) and f(z0 - h)\n",
    "        context['z'] = z0 + h\n",
    "        f_plus = complex(eval(expr_str, {\"__builtins__\": None}, context))\n",
    "        \n",
    "        context['z'] = z0 - h\n",
    "        f_minus = complex(eval(expr_str, {\"__builtins__\": None}, context))\n",
    "\n",
    "        # Central difference formula: f'(z) ≈ (f(z+h) - f(z-h)) / 2h\n",
    "        # Logarithmic derivative: f'/f ≈ (f_plus - f_minus) / (2 * h * f_0)\n",
    "        deriv = (f_plus - f_minus) / (2 * h * f_0)\n",
    "        return deriv\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error evaluating {expr_str} at z={z0}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_random_tau():\n",
    "    real_part = np.random.uniform(-0.5, 0.5)\n",
    "    imag_part = np.random.uniform(0.5, 2.0)  \n",
    "    return complex(real_part, imag_part)\n",
    "\n",
    "def verify_single_sample(expr_origin, expr_simple, threshold=1e-3, max_tau_retries=5):\n",
    "    \n",
    "    num_points = 10\n",
    "    \n",
    "    for tau_attempt in range(max_tau_retries):\n",
    "        if tau_attempt == 0:\n",
    "            t_val = 0.3 + 1.2j\n",
    "        else:\n",
    "            t_val = generate_random_tau()\n",
    "        \n",
    "        np.random.seed(1107 + tau_attempt * 100)\n",
    "        z_samples = np.random.uniform(-0.5, 0.5, num_points) + \\\n",
    "                    1j * np.random.uniform(-0.5, 0.5, num_points)\n",
    "        \n",
    "        diff_values = []\n",
    "        valid_z = []\n",
    "\n",
    "        for z_val in z_samples:\n",
    "            ld_origin = get_log_derivative(expr_origin, z_val, t_val)\n",
    "            ld_simple = get_log_derivative(expr_simple, z_val, t_val)\n",
    "            \n",
    "            if ld_origin is not None and ld_simple is not None:\n",
    "                diff = ld_origin - ld_simple\n",
    "                diff_values.append(diff)\n",
    "                valid_z.append(z_val)\n",
    "\n",
    "        if len(diff_values) >= 5:\n",
    "            break\n",
    "        \n",
    "        if tau_attempt < max_tau_retries - 1:\n",
    "            continue\n",
    "    \n",
    "    if len(diff_values) < 5:\n",
    "        print(f\"[Insufficient valid points, skipping (Tried {max_tau_retries} different tau values)]\")\n",
    "        print(f\"   Origin: {expr_origin}\")\n",
    "        print(f\"   Simple: {expr_simple}\")\n",
    "        return False\n",
    "\n",
    "    X = np.array(valid_z)\n",
    "    y = np.array(diff_values)\n",
    "\n",
    "    A = np.column_stack((X, np.ones_like(X)))\n",
    "    \n",
    "    try:\n",
    "        # Perform linear regression to check for constant or linear differences\n",
    "        coeffs, _, _, _ = np.linalg.lstsq(A, y, rcond=None)\n",
    "        \n",
    "        y_fit = A @ coeffs\n",
    "        residuals = np.abs(y - y_fit)\n",
    "        mean_error = np.mean(residuals)\n",
    "        \n",
    "        is_pass = mean_error < threshold\n",
    "        \n",
    "        # status = \"✅ PASS\" if is_pass else \"❌ FAIL\"\n",
    "        # print(f\"Line : {status} | Linear Fit Error: {mean_error:.2e}\")\n",
    "        if not is_pass:\n",
    "            print(f\"[Fit Failed] Linear Fit Error: {mean_error:.2e}\")\n",
    "            print(f\"   Origin: {expr_origin}\")\n",
    "            print(f\"   Simple: {expr_simple}\")\n",
    "\n",
    "        return is_pass\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error during fitting process] {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c258cc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_single_sample(expr_origin_infix, predicted_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
